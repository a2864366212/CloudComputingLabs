##### Lab2 test report

## 1. 实验概要

&emsp;&emsp;使用从课程中学到的网络编程知识，实现一个基于HTTP/1.1的HTTP服务器，尽量使用从课程中学到的高并发性编程技巧来保证web服务器的性能。实验2将比较不同并发请求用户数的性能差异、不同客户端负载的性能差异以及在不同硬件环境下的性能差异。

### 1.1 程序输入

&emsp;&emsp;通过命令行输入长选项--port 与 --number-thread 的值，以HTTP运行服务器程序。之后可通过浏览器、curl、ab、JMETER等测试工具对服务器的性能进行测试

### 1.2 程序输出

&emsp;&emsp;对于请求资源存在的GET请求报文，将返回包含所请求资源的响应报文。对于符合实验指导书中格式的POST请求，将返回包含回显信息的响应报文。

### 1.3 性能指标

&emsp;&emsp;实验以服务器每秒钟处理的http请求数作为性能指标。更具体的是通过测量每秒点击率(Hits Per Second)来量化服务器性能。

&emsp;&emsp;点击率是每秒钟用户向WEB服务器提交的HTTP请求数.这个指标是WEB应用特有的一个指标:WEB应用是"请求-响应"模式,用户发出一次申请,服务器就要处理一次,所以点击是WEB应用能够处理的交易的最小单位

### 1.4 实验环境

&emsp;&emsp;实验中共有2个不同的实验环境：**ENV1**和**ENV2**。

&emsp;&emsp;**ENV1:** linux内核版本为4.15.0-129-generic；2GB内存；CPU型号为Intel(R) Core(TM) i5-7300HQ CPU @ 2.50GHz，共有2个物理CPU；每个物理CPU有1个物理核心，共有2个物理核心；不使用超线程技术。

&emsp;&emsp;**ENV2:** linux内核版本为4.15.0-129-generic；2GB内存；CPU型号为Intel(R) Core(TM) i5-7300HQ CPU @ 2.50GHz，共有4个物理CPU；每个物理CPU有1个物理核心，共有4个物理核心；不使用超线程技术。

如无特别说明，默认使用ENV2。

### 1.5 代码实现版本

&emsp;&emsp;实验中使用代码：**Code1**

&emsp;&emsp;**Code1:** 线程池（A pool of always-on threads）。在HTTP服务器程序中使用固定大小的线程池来并发处理多个客户机请求。如果没有任务，则这些线程处于等待状态。如果有一个新客户端进入，分配一个线程来处理客户端请求并向它发送响应。

## 2. 性能测试

&emsp;&emsp;程序的性能会受到诸多因素的影响，其中包括软件层面的因素和硬件层面的因素。对于http服务器，客户端、CPU和网络带宽等都可能成为性能瓶颈。本节将分析比较不同并发请求用户数的性能差异、不同客户端负载的性能差异以及在不同硬件环境下的性能差异。

### 2.1 不同并发用户数的性能比较

&emsp;「TPS 」Transactions Per Second 也就是事务数/秒。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，并发数（并发度）：指系统同时能处理的请求数量，反应了系统的负载能力。「吐吞量」：吞吐量是指系统在单位时间内处理请求的数量，TPS是吞吐量的常用量化指标。其中，TPS=并发数/平均响应时间。一个系统吞吐量通常由TPS,并发数两个主要因素决定，每套系统这个两个值都有一个相对极限值，在应用场景访问压力下，只要某一项达到系统最高值，系统吞吐量就上不去了，如果压力继续增大，系统的吞吐量反而会下降，原因是系统超负荷工作，上下文切换，内存等等其他消耗导致系统性能下降。

&emsp;硬件环境使用ENV2，本次测试改变不同的并发用户数（100-10000），并保证每个用户只发送一次请求，但是短时间内可以有大量用户同时发送请求，模拟了短时间内有大量用户同时访问服务器的情形。

&emsp;可以看到，在并发用户数小于5000时，随着并发用户数的提升，吞吐率持续增长，该阶段是客户端成为服务器性能瓶颈，客户端发出的请求数较少，服务器的处理能力可以满足。然后逐渐稳定（用户数在5000到12500之间），该阶段达到服务器处理能力上限。最后当达到一定并发负荷时，继续增多用户数（大约15000开始），吞吐量有小幅下降，该阶段是是服务器超负荷工作，频繁的上下文切换，内存等等其他资源消耗导致系统性能下降。

<div align="center"><img src="src/pic2-1.png" alt="图2-1" title="图2-1" style="zoom:85%;" /></div>

**<p align="center">图2-1 不同并发用户数的性能比较</p>**

### 2.2 不同客户端负载性能比较

&emsp;&emsp;测试对比客户端为新请求使用新的TCP连接（短连接）以及客户端为新请求重用旧TCP连接（长连接）两种工作负载的服务器性能。长连接是客户端与服务器先建立连接，连接建立后不断开，然后再进行报文发送和接收。短连接则是客户端与服务器每进行一次报文收发才建立连接，收发完毕后立即断开连接。长连接多用于操作频繁，而且连接数不太多的情况。每个TCP连接都需要三次握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后不断开，下次就可以直接发送数据包，不用再建立TCP连接，减小了连接建立带来的开销。

&emsp;&emsp;实验中使用 JMETER 测试工具模拟少并发用户数、多次请求的客户端负载情形。通过参数设置，JMETER 会在1s内启动500个并发用户线程，每个用户线程发送num（num的测试序列为[1,10,15,25,75,150,225,250,300,600,900,1500]）次GET请求，并测试点击率。

&emsp;&emsp;图2-2显示了在少量并发用户数、每个用户都频繁进行请求的工作负载下，服务器与客户端分别建立长连接、短连接时的点击率测试结果，其中每个客户端线程请求数不断增加。当每个客户端线程请求数小于75时，使用长连接和短连接的服务器的点击率都快速上升，该阶段是客户端成为服务器性能瓶颈，客户端发出的请求数较少，服务器的处理能力完全可以满足。当客户端线程请求数处于75和900之间时，使用长连接的服务器程序点击率仍在快速上升而使用短连接的服务器程序点击率趋于平稳，这是因为每个TCP连接建立都需要三次握手、断开连接需要四次挥手，使用长连接相比于使用短连接的服务器程序，节省了大量的TCP连接建立、拆除的时间开销。

<div align="center"><img src="src/pic2-2.png" alt="图2-2" title="图2-2" style="zoom:85%;" /></div>

**<p align="center">图2-2 不同客户端负载性能比较</p>**

### 2.3 不同硬件环境性能比较


&emsp;&emsp;在**ENV1**和**ENV2**环境中，改变程序中使用的线程数量，测试在500个用户下，每一个用户通过长连接请求300次的吞吐量。

&emsp;&emsp;图2-3-1显示了CPU核心数量为2核时，吞吐量随着线程数量的变化曲线。可以发现当线程数量从1变为2时，吞吐量也提高了将近2倍，线程数到达3时达到吞吐量的最大值，而继续提高线程数量之后，吞吐量下降，趋于平稳。同样，图2-3-2显示了CPU核心数量4核时吞吐量随线程变化的曲线。线程数量从1变化到4的过程中，吞吐量基本按照线性增长，之后趋于平稳，当线程数到达8时达到吞吐量最大值。并且，双核CPU的机器环境下最大吞吐量大概是四核CPU最大吞吐量的一半。我们分析后认为，对于HTTP服务器这类IO密集型的程序来说，线程数达到CPU核心数的一倍左右才能达到最大CPU效率，因为当一个线程进入IO后，会主动放弃CPU，如果此时该CPU核心上有另一个线程，CPU将会调度另一个线程，保证CPU的完全利用。否则，如果线程数等于CPU核心数，当一个线程进入IO后，CPU将会处于空闲状态，不能保证完全利用。

&emsp;&emsp;此外，实验中我们发现，提供负载测试的软件**JMETER也有很高的CPU占用率**，基本能够占到25%的CPU利用率，这可能是导致当线程数量从1增长到2时，吞吐量增长量远小于1倍的主要原因。

<div align="center"><img src="src/图2-4-1.png" alt="图2-4-1" title="图2-4-1" style="zoom:65%;" /></div>
<p align="center">图2-3-1 2核CPU吞吐量和线程数的关系</p>

<div align="center"><img src="src/图2-4-2.png" alt="图2-4-2" title="图2-4-2" style="zoom:65%;" /></div>
<p align="center">图2-3-2 4核CPU吞吐量和线程数的关系</p>